{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "LinkedIn Selenium Scraper\n",
    "-------------------------\n",
    "Ce script permet de scraper des posts LinkedIn en rapport avec l'IA\n",
    "et d'extraire leurs métriques d'engagement (likes, commentaires, partages)\n",
    "en utilisant un compte LinkedIn existant.\n",
    "\n",
    "Développé pour collecter des données pour fine-tuning.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, StaleElementReferenceException\n",
    "\n",
    "# Configuration des dossiers\n",
    "RESULTS_DIR = 'resultats'\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkedInSeleniumScraper:\n",
    "    \"\"\"Classe pour scraper des posts LinkedIn avec Selenium\"\"\"\n",
    "\n",
    "    def __init__(self, headless=False, user_agent=None):\n",
    "        \"\"\"\n",
    "        Initialise le scraper LinkedIn\n",
    "\n",
    "        Args:\n",
    "            headless (bool): Mode headless (sans interface graphique)\n",
    "            user_agent (str): User agent personnalisé\n",
    "        \"\"\"\n",
    "        self.driver = None\n",
    "        self.headless = headless\n",
    "        self.user_agent = user_agent or \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\n",
    "        self.base_url = \"https://www.linkedin.com\"\n",
    "        self.search_url = \"https://www.linkedin.com/search/results/content/\"\n",
    "        self.posts_data = []\n",
    "        self.is_logged_in = False\n",
    "\n",
    "        # Paramètres de sécurité\n",
    "        self.min_delay = 2.0  # Délai minimum entre les actions (secondes)\n",
    "        self.max_delay = 5.0  # Délai maximum entre les actions (secondes)\n",
    "        self.scroll_delay = 1.5  # Délai après chaque défilement\n",
    "        self.max_posts_per_search = 20  # Nombre maximum de posts par recherche\n",
    "        self.max_searches_per_session = 5  # Nombre maximum de recherches par session\n",
    "\n",
    "        # Initialiser le navigateur\n",
    "        self._setup_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _setup_driver(self):\n",
    "        \"\"\"Configure le driver Selenium avec les options appropriées\"\"\"\n",
    "        chrome_options = Options()\n",
    "\n",
    "        if self.headless:\n",
    "            chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "        # Options pour éviter la détection\n",
    "        chrome_options.add_argument(f\"user-agent={self.user_agent}\")\n",
    "        chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "        chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "        chrome_options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "\n",
    "        # Options supplémentaires\n",
    "        chrome_options.add_argument(\"--no-sandbox\")\n",
    "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "\n",
    "        # Créer le driver\n",
    "        # Assurez-vous que chromedriver est dans le PATH ou spécifiez le chemin avec Service\n",
    "        # service = Service('/path/to/chromedriver')\n",
    "        # self.driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "        self.driver = webdriver.Chrome(options=chrome_options) # Simplifié si chromedriver est dans le PATH\n",
    "\n",
    "        # Modifier les propriétés du navigateur pour éviter la détection\n",
    "        self.driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "\n",
    "        # Définir un timeout par défaut\n",
    "        self.driver.implicitly_wait(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloc 4 : Méthodes Utilitaires de Temporisation et Simulation\n",
    "\n",
    "# ---- Ajoute un délai aléatoire entre les actions pour simuler un comportement humain ----\n",
    "def _random_delay(self):\n",
    "    \"\"\"Ajoute un délai aléatoire entre les actions pour simuler un comportement humain\"\"\"\n",
    "    delay = random.uniform(self.min_delay, self.max_delay)\n",
    "    time.sleep(delay)\n",
    "\n",
    "# ---- Simule un défilement humain sur la page ----\n",
    "def _simulate_human_scroll(self, scroll_count=3):\n",
    "    \"\"\"Simule un défilement humain sur la page\"\"\"\n",
    "    for _ in range(scroll_count):\n",
    "        # Défilement aléatoire\n",
    "        scroll_amount = random.randint(300, 700)\n",
    "        # La ligne suivante doit être correctement indentée sous le 'for'\n",
    "        self.driver.execute_script(f\"window.scrollBy(0, {scroll_amount});\")\n",
    "        time.sleep(self.scroll_delay)  # Cette ligne aussi\n",
    "\n",
    "# ---- Simule une saisie humaine avec des délais aléatoires entre les caractères ----\n",
    "def _type_like_human(self, element, text):\n",
    "    \"\"\"Simule une saisie humaine avec des délais aléatoires entre les caractères\"\"\"\n",
    "    for char in text:\n",
    "        element.send_keys(char)\n",
    "        time.sleep(random.uniform(0.05, 0.25))  # Cette ligne aussi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login(self, email, password):\n",
    "        \"\"\"\n",
    "        Se connecte à LinkedIn avec les identifiants fournis\n",
    "\n",
    "        Args:\n",
    "            email (str): Email du compte LinkedIn\n",
    "            password (str): Mot de passe du compte LinkedIn\n",
    "\n",
    "        Returns:\n",
    "            bool: True si la connexion a réussi, False sinon\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"Connexion à LinkedIn...\")\n",
    "            self.driver.get(f\"{self.base_url}/login\")\n",
    "            self._random_delay()\n",
    "\n",
    "            # Remplir le formulaire de connexion\n",
    "            email_field = self.driver.find_element(By.ID, \"username\")\n",
    "            password_field = self.driver.find_element(By.ID, \"password\")\n",
    "\n",
    "            # Simuler une saisie humaine\n",
    "            self._type_like_human(email_field, email)\n",
    "            self._random_delay()\n",
    "            self._type_like_human(password_field, password)\n",
    "            self._random_delay()\n",
    "\n",
    "            # Cliquer sur le bouton de connexion\n",
    "            login_button = self.driver.find_element(By.XPATH, \"//button[@type='submit']\")\n",
    "            login_button.click()\n",
    "\n",
    "            # Attendre que la page d'accueil se charge (ajustez le sélecteur si nécessaire)\n",
    "            WebDriverWait(self.driver, 30).until(\n",
    "                EC.presence_of_element_located((By.ID, \"global-nav\")) # Ou un autre élément stable de la page post-connexion\n",
    "            )\n",
    "\n",
    "            print(\"Connexion réussie!\")\n",
    "            self.is_logged_in = True\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la connexion: {e}\")\n",
    "            # Sauvegarder une capture d'écran peut être utile pour le débogage\n",
    "            # self.driver.save_screenshot(\"login_error.png\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_posts(self, keyword, language=\"fr\"):\n",
    "        \"\"\"\n",
    "        Recherche des posts LinkedIn avec le mot-clé spécifié\n",
    "\n",
    "        Args:\n",
    "            keyword (str): Mot-clé à rechercher\n",
    "            language (str): Langue des posts (fr pour français) - Note: L'API de recherche peut changer\n",
    "\n",
    "        Returns:\n",
    "            list: Liste des URLs des posts trouvés\n",
    "        \"\"\"\n",
    "        if not self.is_logged_in:\n",
    "            print(\"Vous devez être connecté pour effectuer une recherche\")\n",
    "            return []\n",
    "\n",
    "        try:\n",
    "            print(f\"Recherche de posts avec le mot-clé: {keyword}\")\n",
    "\n",
    "            # Construire l'URL de recherche (simplifiée)\n",
    "            search_query = keyword.replace(\" \", \"%20\")\n",
    "            # L'URL de recherche et les paramètres peuvent changer fréquemment sur LinkedIn\n",
    "            url = f\"{self.search_url}?keywords={search_query}&origin=GLOBAL_SEARCH_HEADER&sortBy=relevance\"\n",
    "            # Ajouter des filtres peut nécessiter des ajustements basés sur l'interface actuelle de LinkedIn\n",
    "            # if language:\n",
    "            #    url += f\"&facetGeoRegion=fr%3A0\" # Exemple, à vérifier\n",
    "\n",
    "            self.driver.get(url)\n",
    "            self._random_delay()\n",
    "\n",
    "            # Simuler un comportement humain et charger les posts\n",
    "            self._simulate_human_scroll(scroll_count=5) # Augmenter le scroll pour plus de résultats\n",
    "\n",
    "            # Extraire les posts\n",
    "            post_urls = []\n",
    "            # Les sélecteurs XPath peuvent devenir obsolètes, à vérifier régulièrement\n",
    "            post_elements = self.driver.find_elements(By.XPATH, \"//div[contains(@class, 'feed-shared-update-v2')] | //li[contains(@class, 'reusable-search__result-container')]\") # Ajustement possible du sélecteur\n",
    "\n",
    "            print(f\"Nombre d'éléments trouvés correspondant aux posts potentiels: {len(post_elements)}\")\n",
    "\n",
    "            for post in post_elements[:self.max_posts_per_search]:\n",
    "                try:\n",
    "                    # Trouver l'URL du post - S'assurer que le lien contient bien /posts/ ou /feed/update/urn:li:activity:\n",
    "                    # Il peut y avoir plusieurs liens, on cherche celui du post lui-même\n",
    "                    post_link_elements = post.find_elements(By.XPATH, \".//a[contains(@href, '/posts/') or contains(@href, '/feed/update/urn:li:activity:')]\")\n",
    "                    post_url = None\n",
    "                    if post_link_elements:\n",
    "                         # Souvent le premier lien ou un lien spécifique contient l'URL canonique\n",
    "                        post_url = post_link_elements[0].get_attribute(\"href\")\n",
    "                        # Nettoyer l'URL (enlever les query params superflus)\n",
    "                        if post_url and \"?\" in post_url:\n",
    "                            post_url = post_url.split(\"?\")[0]\n",
    "\n",
    "                    if post_url and (\"/posts/\" in post_url or \"/feed/update/urn:li:activity:\" in post_url):\n",
    "                        if post_url not in post_urls: # Éviter les doublons immédiats\n",
    "                             post_urls.append(post_url)\n",
    "                             print(f\"Post URL trouvée : {post_url}\")\n",
    "\n",
    "\n",
    "                except (NoSuchElementException, StaleElementReferenceException) as e:\n",
    "                    print(f\"Erreur lors de l'extraction de l'URL d'un post: {e}\")\n",
    "                    continue\n",
    "                except Exception as e_gen:\n",
    "                    print(f\"Erreur générale lors du traitement d'un élément de post: {e_gen}\")\n",
    "                    continue\n",
    "\n",
    "\n",
    "            print(f\"Trouvé {len(post_urls)} URLs de posts uniques pour le mot-clé '{keyword}'\")\n",
    "            return post_urls\n",
    "\n",
    "        except TimeoutException:\n",
    "             print(\"Timeout lors de la recherche des posts.\")\n",
    "             return []\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur majeure lors de la recherche: {e}\")\n",
    "            # self.driver.save_screenshot(\"search_error.png\")\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_post_data(self, post_url):\n",
    "        \"\"\"\n",
    "        Extrait les données d'un post LinkedIn\n",
    "\n",
    "        Args:\n",
    "            post_url (str): URL du post LinkedIn\n",
    "\n",
    "        Returns:\n",
    "            dict: Données du post (texte, auteur, date, métriques d'engagement) ou None si erreur majeure\n",
    "        \"\"\"\n",
    "        if not self.is_logged_in:\n",
    "            print(\"Vous devez être connecté pour extraire les données d'un post\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            print(f\"Extraction des données du post: {post_url}\")\n",
    "            self.driver.get(post_url)\n",
    "            self._random_delay()\n",
    "\n",
    "            # Attendre que le contenu principal du post soit chargé\n",
    "            try:\n",
    "                WebDriverWait(self.driver, 20).until(\n",
    "                     EC.presence_of_element_located((By.XPATH, \"//main | //div[contains(@class, 'core-rail')]\")) # Attendre l'élément principal\n",
    "                )\n",
    "            except TimeoutException:\n",
    "                 print(f\"Timeout en attendant le chargement principal du post: {post_url}\")\n",
    "                 # Tenter de continuer ou retourner une erreur\n",
    "                 # return None # Option: abandonner si la page principale ne charge pas\n",
    "\n",
    "            # Simuler un comportement humain\n",
    "            self._simulate_human_scroll(scroll_count=2)\n",
    "\n",
    "            # Initialiser les données du post\n",
    "            post_data = {\n",
    "                \"url\": post_url,\n",
    "                \"text\": \"\",\n",
    "                \"author\": \"\",\n",
    "                \"date\": \"\",\n",
    "                \"likes\": 0,\n",
    "                \"comments\": 0,\n",
    "                \"shares\": 0, # Les partages sont souvent difficiles à obtenir/non affichés directement\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"error\": None\n",
    "            }\n",
    "\n",
    "            # Extraire le texte du post (plusieurs sélecteurs possibles)\n",
    "            try:\n",
    "                # Attendre spécifiquement l'élément de texte\n",
    "                 post_text_element = WebDriverWait(self.driver, 15).until(\n",
    "                     EC.presence_of_element_located((\n",
    "                         By.XPATH,\n",
    "                         \"//div[contains(@class, 'update-components-text')]//span[@dir='ltr'] | \" # Nouveau sélecteur potentiel\n",
    "                         \"//div[contains(@class, 'feed-shared-update-v2__description-wrapper')]//span | \"\n",
    "                         \"//div[contains(@class, 'attributed-text-segment-list__container')] |\" # Autre possibilité\n",
    "                         \"//div[@class='feed-shared-update-v2__commentary']\" # Ancien sélecteur\n",
    "                     ))\n",
    "                 )\n",
    "                 post_data[\"text\"] = post_text_element.text.strip()\n",
    "            except (TimeoutException, NoSuchElementException) as e:\n",
    "                print(f\"Impossible de trouver le texte du post: {e}\")\n",
    "                post_data[\"error\"] = \"Text extraction failed\"\n",
    "\n",
    "\n",
    "            # Extraire l'auteur du post\n",
    "            try:\n",
    "                 author_element = self.driver.find_element(By.XPATH, \"//span[contains(@class, 'update-components-actor__name')]//span[@dir='ltr'] | //a[contains(@class, 'update-components-actor__meta-link')]//span | //span[contains(@class, 'feed-shared-actor__name')]\") # Sélecteurs multiples\n",
    "                 post_data[\"author\"] = author_element.text.strip()\n",
    "            except NoSuchElementException:\n",
    "                 print(\"Impossible de trouver l'auteur du post.\")\n",
    "                 if post_data[\"error\"] is None: post_data[\"error\"] = \"Author extraction failed\"\n",
    "\n",
    "\n",
    "            # Extraire la date/heure du post (peut être relatif, ex: \"2 h\")\n",
    "            try:\n",
    "                 # Le lien contient souvent un horodatage plus précis dans l'attribut href ou un span caché\n",
    "                 date_element = self.driver.find_element(By.XPATH, \"//a[contains(@class, 'update-components-actor__sub-description-link')]//span | //span[contains(@class, 'feed-shared-actor__sub-description')]//span[contains(@class, 'visually-hidden')] | //span[contains(@class, 'feed-shared-actor__sub-description')]\")\n",
    "                 post_data[\"date\"] = date_element.text.strip() # Peut nécessiter un parsing plus avancé pour convertir en date absolue\n",
    "            except NoSuchElementException:\n",
    "                 print(\"Impossible de trouver la date du post.\")\n",
    "                 if post_data[\"error\"] is None: post_data[\"error\"] = \"Date extraction failed\"\n",
    "\n",
    "            # Extraire les métriques d'engagement\n",
    "            likes = 0\n",
    "            comments = 0\n",
    "            shares = 0 # Moins fiable\n",
    "            try:\n",
    "                # Chercher le conteneur des réactions/commentaires\n",
    "                 social_counts_container = self.driver.find_element(By.XPATH, \"//div[contains(@class, 'social-details-social-counts')] | //ul[contains(@class, 'social-details-social-counts')]\")\n",
    "\n",
    "                 # Extraire le nombre de likes/réactions\n",
    "                 try:\n",
    "                     likes_element = social_counts_container.find_element(By.XPATH, \".//button[contains(@aria-label, 'reaction')] | .//span[contains(@class,'reactions-count')] | .//li[contains(@class, 'social-details-social-counts__reactions')]//span\") # Plusieurs possibilités\n",
    "                     likes_text = likes_element.text.strip() or likes_element.get_attribute('aria-label') # Parfois dans aria-label\n",
    "                     likes = self._parse_count(likes_text)\n",
    "                 except NoSuchElementException:\n",
    "                      print(\"Likes non trouvés.\")\n",
    "\n",
    "\n",
    "                 # Extraire le nombre de commentaires\n",
    "                 try:\n",
    "                     comments_element = social_counts_container.find_element(By.XPATH, \".//button[contains(@aria-label, 'commentaires')] | .//li[contains(@class, 'social-details-social-counts__comments')]//span | .//a[contains(@href, 'comments')]\")\n",
    "                     comments_text = comments_element.text.strip() or comments_element.get_attribute('aria-label')\n",
    "                     comments = self._parse_count(comments_text)\n",
    "                 except NoSuchElementException:\n",
    "                     print(\"Commentaires non trouvés.\")\n",
    "\n",
    "                 # Extraire le nombre de partages (si disponible)\n",
    "                 try:\n",
    "                     shares_element = social_counts_container.find_element(By.XPATH, \".//button[contains(@aria-label, 'reposts')] | .//li[contains(@class, 'social-details-social-counts__shares')]//span | .//li[contains(@class, 'social-details-social-counts__reposts')]//span\") # Reposts sont les nouveaux partages\n",
    "                     shares_text = shares_element.text.strip() or shares_element.get_attribute('aria-label')\n",
    "                     shares = self._parse_count(shares_text)\n",
    "                 except NoSuchElementException:\n",
    "                     print(\"Partages/Reposts non trouvés.\")\n",
    "\n",
    "\n",
    "            except NoSuchElementException:\n",
    "                print(\"Conteneur des métriques sociales non trouvé.\")\n",
    "                if post_data[\"error\"] is None: post_data[\"error\"] = \"Social metrics container not found\"\n",
    "\n",
    "\n",
    "            post_data[\"likes\"] = likes\n",
    "            post_data[\"comments\"] = comments\n",
    "            post_data[\"shares\"] = shares # Peut rester 0\n",
    "\n",
    "            print(f\"Données extraites: Likes={likes}, Comments={comments}, Shares={shares}\")\n",
    "            return post_data\n",
    "\n",
    "        except TimeoutException as e:\n",
    "             print(f\"Timeout lors de l'extraction des données du post {post_url}: {e}\")\n",
    "             return {\"url\": post_url, \"error\": f\"Timeout: {e}\", \"timestamp\": datetime.now().isoformat()}\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur majeure lors de l'extraction des données du post {post_url}: {e}\")\n",
    "            # self.driver.save_screenshot(f\"extract_error_{post_url.split('/')[-2]}.png\")\n",
    "            return {\"url\": post_url, \"error\": f\"General extraction error: {e}\", \"timestamp\": datetime.now().isoformat()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_count(self, count_text):\n",
    "        \"\"\"\n",
    "        Convertit un texte de compteur en nombre (gère les 'k', 'm', ',', et le texte additionnel).\n",
    "\n",
    "        Args:\n",
    "            count_text (str): Texte du compteur (ex: \"1,2k réactions\", \"45 commentaires\", \"1.5M\")\n",
    "\n",
    "        Returns:\n",
    "            int: Nombre converti\n",
    "        \"\"\"\n",
    "        if not count_text:\n",
    "            return 0\n",
    "\n",
    "        # Extraire la partie numérique au début de la chaîne\n",
    "        import re\n",
    "        match = re.match(r\"([\\d.,]+)\\s?([km])?\", count_text.lower().replace(',', ''))\n",
    "        if not match:\n",
    "             # Essayer de trouver un nombre n'importe où dans la chaîne (moins précis)\n",
    "             num_match = re.search(r\"([\\d.,]+)\", count_text.replace(',', ''))\n",
    "             if num_match:\n",
    "                 try:\n",
    "                     return int(float(num_match.group(1)))\n",
    "                 except ValueError:\n",
    "                      return 0\n",
    "             else:\n",
    "                 return 0\n",
    "\n",
    "\n",
    "        number_part = match.group(1)\n",
    "        multiplier_char = match.group(2)\n",
    "\n",
    "        try:\n",
    "            number = float(number_part)\n",
    "            if multiplier_char == 'k':\n",
    "                number *= 1000\n",
    "            elif multiplier_char == 'm':\n",
    "                number *= 1000000\n",
    "            return int(number)\n",
    "        except ValueError:\n",
    "            return 0 # Retourne 0 si la conversion échoue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_posts_data(self, keywords, max_posts_total=100):\n",
    "        \"\"\"\n",
    "        Collecte les données de posts LinkedIn pour une liste de mots-clés.\n",
    "\n",
    "        Args:\n",
    "            keywords (list): Liste de mots-clés à rechercher.\n",
    "            max_posts_total (int): Nombre maximum total de posts à collecter sur l'ensemble des mots-clés.\n",
    "\n",
    "        Returns:\n",
    "            list: Liste des données de posts collectées.\n",
    "        \"\"\"\n",
    "        if not self.is_logged_in:\n",
    "            print(\"Vous devez être connecté pour collecter des données\")\n",
    "            return []\n",
    "\n",
    "        all_post_urls = []\n",
    "        search_count = 0\n",
    "        self.posts_data = [] # Réinitialiser les données collectées pour cet appel\n",
    "\n",
    "        print(f\"Début de la collecte pour les mots-clés: {keywords}\")\n",
    "        print(f\"Limite de recherches par session: {self.max_searches_per_session}\")\n",
    "        print(f\"Limite de posts par recherche: {self.max_posts_per_search}\")\n",
    "        print(f\"Limite totale de posts à extraire: {max_posts_total}\")\n",
    "\n",
    "\n",
    "        # Limiter le nombre de recherches par session\n",
    "        for keyword in keywords:\n",
    "            if search_count >= self.max_searches_per_session:\n",
    "                print(f\"Limite de {self.max_searches_per_session} recherches atteinte pour cette session.\")\n",
    "                break\n",
    "\n",
    "            if len(self.posts_data) >= max_posts_total:\n",
    "                 print(f\"Limite totale de {max_posts_total} posts à extraire atteinte.\")\n",
    "                 break\n",
    "\n",
    "\n",
    "            print(f\"\\n--- Recherche {search_count + 1}/{self.max_searches_per_session} --- Mot-clé: '{keyword}' ---\")\n",
    "            # Rechercher des posts pour le mot-clé\n",
    "            post_urls_found = self.search_posts(keyword) # Utilise self.max_posts_per_search\n",
    "            all_post_urls.extend(post_urls_found)\n",
    "            search_count += 1\n",
    "\n",
    "            # Ajouter un délai plus long entre les recherches pour éviter les blocages\n",
    "            print(f\"Pause après la recherche pour '{keyword}'...\")\n",
    "            time.sleep(random.uniform(8.0, 15.0)) # Délai plus long entre les recherches\n",
    "\n",
    "        # Dédupliquer les URLs collectées sur l'ensemble des recherches\n",
    "        unique_post_urls = list(dict.fromkeys(all_post_urls)) # Maintient l'ordre et déduplique\n",
    "        print(f\"\\nNombre total d'URLs uniques trouvées après déduplication: {len(unique_post_urls)}\")\n",
    "\n",
    "\n",
    "        # Limiter le nombre total de posts dont on va extraire les données\n",
    "        post_urls_to_process = unique_post_urls[:min(len(unique_post_urls), max_posts_total)]\n",
    "        print(f\"Nombre d'URLs de posts à traiter (limité par max_posts_total={max_posts_total}): {len(post_urls_to_process)}\")\n",
    "\n",
    "\n",
    "        # Extraire les données pour chaque post unique\n",
    "        extracted_count = 0\n",
    "        for i, post_url in enumerate(post_urls_to_process):\n",
    "             if extracted_count >= max_posts_total:\n",
    "                 print(f\"Limite totale de {max_posts_total} posts extraits atteinte.\")\n",
    "                 break\n",
    "\n",
    "             print(f\"\\n--- Extraction {i + 1}/{len(post_urls_to_process)} --- URL: {post_url} ---\")\n",
    "             post_data = self.extract_post_data(post_url)\n",
    "             if post_data: # Vérifier si l'extraction a retourné quelque chose (pas None)\n",
    "                 self.posts_data.append(post_data)\n",
    "                 extracted_count += 1\n",
    "                 # Ajouter un délai entre l'extraction de chaque post\n",
    "                 print(\"Pause après l'extraction...\")\n",
    "                 self._random_delay() # Utilise min_delay et max_delay définis dans __init__\n",
    "\n",
    "\n",
    "        print(f\"\\nCollecte terminée. {len(self.posts_data)} posts ont été traités.\")\n",
    "        return self.posts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(self, filename_base=\"linkedin_posts\", format=\"json\"):\n",
    "    \"\"\"\n",
    "    Sauvegarde les données collectées dans un fichier.\n",
    "\n",
    "    Args:\n",
    "        filename_base (str): Nom de base pour le fichier de sortie.\n",
    "        format (str): Format de sortie ('json' ou 'csv').\n",
    "    \"\"\"\n",
    "    if not self.posts_data:\n",
    "        print(\"Aucune donnée à sauvegarder.\")\n",
    "        return\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = os.path.join(RESULTS_DIR, f\"{filename_base}_{timestamp}.{format}\")\n",
    "\n",
    "    print(f\"Sauvegarde des données dans {filename}...\")\n",
    "\n",
    "    try:\n",
    "        if format == \"json\":\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(self.posts_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        elif format == \"csv\":\n",
    "            df = pd.DataFrame(self.posts_data)\n",
    "\n",
    "            # S'assurer que toutes les colonnes attendues existent, même si vides\n",
    "            expected_columns = [\"url\", \"text\", \"author\", \"date\", \"Likes\", \"comments\", \"shares\", \"timestamp\", \"error\"]\n",
    "            for col in expected_columns:\n",
    "                if col not in df.columns:\n",
    "                    df[col] = None  # Valeur par défaut si la colonne est absente\n",
    "\n",
    "            # Réorganiser les colonnes\n",
    "            df = df[expected_columns]\n",
    "            df.to_csv(filename, index=False, encoding='utf-8-sig')  # utf-8-sig pour Excel\n",
    "\n",
    "        else:\n",
    "            print(f\"Format de fichier non supporté: {format}. Choisissez 'json' ou 'csv'.\")\n",
    "            return\n",
    "\n",
    "        print(f\"Données sauvegardées avec succès dans {filename} ✅\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la sauvegarde des données : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_driver(self):\n",
    "        \"\"\"Ferme le navigateur Selenium\"\"\"\n",
    "        if self.driver:\n",
    "            try:\n",
    "                print(\"Fermeture du navigateur...\")\n",
    "                self.driver.quit()\n",
    "                self.driver = None\n",
    "                print(\"Navigateur fermé.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur lors de la fermeture du navigateur: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -e EMAIL -p PASSWORD\n",
      "                             [-k KEYWORDS [KEYWORDS ...]] [--headless]\n",
      "                             [-n NUM_POSTS] [-f {json,csv}]\n",
      "                             [--user_agent USER_AGENT]\n",
      "ipykernel_launcher.py: error: argument -f/--format: invalid choice: '/Users/Nicolas/Library/Jupyter/runtime/kernel-v34e57c1712cc9431b72d40004cf76315143e531ae.json' (choose from 'json', 'csv')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.8.10/lib/python3.8/argparse.py:1800\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1800\u001b[0m     namespace, args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_known_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1801\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(namespace, _UNRECOGNIZED_ARGS_ATTR):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.10/lib/python3.8/argparse.py:2006\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args\u001b[0;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[1;32m   2005\u001b[0m     \u001b[38;5;66;03m# consume the next optional and any arguments for it\u001b[39;00m\n\u001b[0;32m-> 2006\u001b[0m     start_index \u001b[38;5;241m=\u001b[39m \u001b[43mconsume_optional\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2008\u001b[0m \u001b[38;5;66;03m# consume any positionals following the last Optional\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.10/lib/python3.8/argparse.py:1946\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args.<locals>.consume_optional\u001b[0;34m(start_index)\u001b[0m\n\u001b[1;32m   1945\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action, args, option_string \u001b[38;5;129;01min\u001b[39;00m action_tuples:\n\u001b[0;32m-> 1946\u001b[0m     \u001b[43mtake_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moption_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stop\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.10/lib/python3.8/argparse.py:1858\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args.<locals>.take_action\u001b[0;34m(action, argument_strings, option_string)\u001b[0m\n\u001b[1;32m   1857\u001b[0m seen_actions\u001b[38;5;241m.\u001b[39madd(action)\n\u001b[0;32m-> 1858\u001b[0m argument_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margument_strings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;66;03m# error if this argument is not allowed with other previously\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \u001b[38;5;66;03m# seen arguments, assuming that actions that use the default\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;66;03m# value don't really count as \"present\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.10/lib/python3.8/argparse.py:2390\u001b[0m, in \u001b[0;36mArgumentParser._get_values\u001b[0;34m(self, action, arg_strings)\u001b[0m\n\u001b[1;32m   2389\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(action, arg_string)\n\u001b[0;32m-> 2390\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2392\u001b[0m \u001b[38;5;66;03m# REMAINDER arguments convert all values, checking none\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.10/lib/python3.8/argparse.py:2446\u001b[0m, in \u001b[0;36mArgumentParser._check_value\u001b[0;34m(self, action, value)\u001b[0m\n\u001b[1;32m   2445\u001b[0m msg \u001b[38;5;241m=\u001b[39m _(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvalid choice: \u001b[39m\u001b[38;5;132;01m%(value)r\u001b[39;00m\u001b[38;5;124m (choose from \u001b[39m\u001b[38;5;132;01m%(choices)s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2446\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ArgumentError(action, msg \u001b[38;5;241m%\u001b[39m args)\n",
      "\u001b[0;31mArgumentError\u001b[0m: argument -f/--format: invalid choice: '/Users/Nicolas/Library/Jupyter/runtime/kernel-v34e57c1712cc9431b72d40004cf76315143e531ae.json' (choose from 'json', 'csv')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[12], line 13\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# ✅ Utilisation de parse_known_args pour éviter les conflits avec Jupyter\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m args, unknown \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_known_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Créer et exécuter le scraper\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.10/lib/python3.8/argparse.py:1807\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1806\u001b[0m err \u001b[38;5;241m=\u001b[39m _sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m-> 1807\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.10/lib/python3.8/argparse.py:2521\u001b[0m, in \u001b[0;36mArgumentParser.error\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2520\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprog\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprog, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m: message}\n\u001b[0;32m-> 2521\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%(prog)s\u001b[39;49;00m\u001b[38;5;124;43m: error: \u001b[39;49m\u001b[38;5;132;43;01m%(message)s\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.10/lib/python3.8/argparse.py:2508\u001b[0m, in \u001b[0;36mArgumentParser.exit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2507\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_print_message(message, _sys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m-> 2508\u001b[0m \u001b[43m_sys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/linkedin_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2095\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[1;32m   2093\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2094\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 2095\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2096\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2098\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2099\u001b[0m         \u001b[38;5;66;03m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[1;32m   2100\u001b[0m         \u001b[38;5;66;03m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[1;32m   2101\u001b[0m         \u001b[38;5;66;03m# in the engines. This should return a list of strings.\u001b[39;00m\n",
      "File \u001b[0;32m~/linkedin_env/lib/python3.8/site-packages/IPython/core/ultratb.py:696\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[1;32m    689\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \n\u001b[1;32m    691\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/linkedin_env/lib/python3.8/site-packages/IPython/core/ultratb.py:559\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    556\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    557\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    558\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 559\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    563\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[1;32m    567\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m~/linkedin_env/lib/python3.8/site-packages/IPython/core/ultratb.py:1396\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1395\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[0;32m-> 1396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/linkedin_env/lib/python3.8/site-packages/IPython/core/ultratb.py:1287\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1284\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[1;32m   1286\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m~/linkedin_env/lib/python3.8/site-packages/IPython/core/ultratb.py:1140\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1133\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   1138\u001b[0m ):\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1140\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1143\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m~/linkedin_env/lib/python3.8/site-packages/IPython/core/ultratb.py:1030\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m   1028\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[1;32m   1029\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1030\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m   1031\u001b[0m )\n\u001b[1;32m   1033\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1034\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/linkedin_env/lib/python3.8/site-packages/IPython/core/ultratb.py:1098\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1098\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[1;32m   1099\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Configuration de l’analyse des arguments\n",
    "    parser = argparse.ArgumentParser(description=\"Scraper de posts LinkedIn sur l’IA.\")\n",
    "    parser.add_argument(\"-e\", \"--email\", required=True, help=\"Email du compte LinkedIn.\")\n",
    "    parser.add_argument(\"-p\", \"--password\", required=True, help=\"Mot de passe du compte LinkedIn.\")\n",
    "    parser.add_argument(\"-k\", \"--keywords\", nargs=\"+\", default=[\"intelligence artificielle\", \"machine learning\", \"deep learning\"], help=\"Mots-clés pour la recherche.\")\n",
    "    parser.add_argument(\"--headless\", action=\"store_true\", help=\"Exécuter en mode headless (sans interface graphique).\")\n",
    "    parser.add_argument(\"-n\", \"--num_posts\", type=int, default=10, help=\"Nombre maximum total de posts à scraper.\")\n",
    "    parser.add_argument(\"-f\", \"--format\", choices=[\"json\", \"csv\"], default=\"csv\", help=\"Format de sortie des données.\")\n",
    "    parser.add_argument(\"--user_agent\", help=\"User agent personnalisé à utiliser.\")\n",
    "\n",
    "    # ✅ Utilisation de parse_known_args pour éviter les conflits avec Jupyter\n",
    "    args, unknown = parser.parse_known_args()\n",
    "\n",
    "    # Créer et exécuter le scraper\n",
    "    scraper = None\n",
    "    try:\n",
    "        print(\"Initialisation du scraper...\")\n",
    "        scraper = LinkedInSeleniumScraper(\n",
    "            headless=args.headless,\n",
    "            user_agent=args.user_agent\n",
    "        )\n",
    "\n",
    "        # Connexion\n",
    "        if scraper.login(args.email, args.password):\n",
    "            # Collecte des données\n",
    "            collected_data = scraper.collect_posts_data(args.keywords, max_posts_total=args.num_posts)\n",
    "\n",
    "            # Sauvegarde des données (si des données ont été collectées)\n",
    "            if collected_data:\n",
    "                scraper.save_data(filename_base=\"linkedin_ia_posts\", format=args.format)\n",
    "            else:\n",
    "                print(\"Aucune donnée n’a été collectée ou extraite.\")\n",
    "        else:\n",
    "            print(\"Échec de la connexion. Arrêt du script.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Une erreur inattendue est survenue dans le script principal : {e}\")\n",
    "\n",
    "    finally:\n",
    "        # Assurer la fermeture du driver même en cas d’erreur\n",
    "        if scraper:\n",
    "            scraper.close_driver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = [\n",
    "    \"\",  # nom fictif du script\n",
    "    \"-e\", \"monemail@exemple.com\",\n",
    "    \"-p\", \"monmotdepasse\",\n",
    "    \"-k\", \"intelligence artificielle\", \"IA\", \"ChatGPT\",\n",
    "    \"--num_posts\", \"10\",\n",
    "    \"--format\", \"csv\",\n",
    "    \"--headless\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialisation du scraper...\n",
      "❌ Une erreur inattendue est survenue dans le script principal : 'LinkedInSeleniumScraper' object has no attribute '_setup_driver'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Configuration de l’analyse des arguments\n",
    "    parser = argparse.ArgumentParser(description=\"Scraper de posts LinkedIn sur l’IA.\")\n",
    "    parser.add_argument(\"-e\", \"--email\", required=True, help=\"Email du compte LinkedIn.\")\n",
    "    parser.add_argument(\"-p\", \"--password\", required=True, help=\"Mot de passe du compte LinkedIn.\")\n",
    "    parser.add_argument(\"-k\", \"--keywords\", nargs=\"+\", default=[\"intelligence artificielle\", \"machine learning\", \"deep learning\"], help=\"Mots-clés pour la recherche.\")\n",
    "    parser.add_argument(\"--headless\", action=\"store_true\", help=\"Exécuter en mode headless (sans interface graphique).\")\n",
    "    parser.add_argument(\"-n\", \"--num_posts\", type=int, default=10, help=\"Nombre maximum total de posts à scraper.\")\n",
    "    \n",
    "    # 🔥 On évite le conflit avec le `-f` de Jupyter en supprimant l'alias court\n",
    "    parser.add_argument(\"--format\", choices=[\"json\", \"csv\"], default=\"csv\", help=\"Format de sortie des données.\")\n",
    "\n",
    "    parser.add_argument(\"--user_agent\", help=\"User agent personnalisé à utiliser.\")\n",
    "\n",
    "    # ✅ parse_known_args pour ne pas planter avec les arguments système de Jupyter\n",
    "    args, unknown = parser.parse_known_args()\n",
    "\n",
    "    # Créer et exécuter le scraper\n",
    "    scraper = None\n",
    "    try:\n",
    "        print(\"Initialisation du scraper...\")\n",
    "        scraper = LinkedInSeleniumScraper(\n",
    "            headless=args.headless,\n",
    "            user_agent=args.user_agent\n",
    "        )\n",
    "\n",
    "        # Connexion\n",
    "        if scraper.login(args.email, args.password):\n",
    "            print(\"Connexion réussie.\")\n",
    "            collected_data = scraper.collect_posts_data(args.keywords, max_posts_total=args.num_posts)\n",
    "\n",
    "            if collected_data:\n",
    "                scraper.save_data(filename_base=\"linkedin_ia_posts\", format=args.format)\n",
    "            else:\n",
    "                print(\"Aucune donnée n’a été collectée ou extraite.\")\n",
    "        else:\n",
    "            print(\"Échec de la connexion. Arrêt du script.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Une erreur inattendue est survenue dans le script principal : {e}\")\n",
    "\n",
    "    finally:\n",
    "        if scraper:\n",
    "            scraper.close_driver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linkedin_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
